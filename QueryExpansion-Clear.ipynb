{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0) Just some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import common as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Simple search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1) Get acquainted with the below class. There are several TODOs. However, DO NOT complete them now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['aaai', 'about', 'academic', 'access', 'acquired', 'acquisition', 'action', 'activity', 'actual', 'adaptive', 'add', 'advance', 'agricultural', 'aha', 'aim', 'alert', 'algorithm', 'all', 'analysis', 'and', 'announcement', 'answer', 'anyone', 'application', 'applied', 'apply', 'applying', 'approach', 'approache', 'april', 'archive', 'are', 'area', 'areas', 'article', 'artificial', 'asked', 'august', 'author', 'automated', 'automatically', 'autonomous', 'available', 'awards', 'backend', 'backgammon', 'baldi', 'based', 'basic', 'bayesian']\n"
    }
   ],
   "source": [
    "class Dictionary:\n",
    "    def __init__(self):\n",
    "        ### keeps unique terms (SORTED!)\n",
    "        self.terms = self.loadTerms(\"terms.txt\")\n",
    "        self.idfs = [] ### IDF coefficients\n",
    "        self.corM = [] ### a correlation matrix\n",
    "\n",
    "    ### load terms\n",
    "    def loadTerms(self, fileName):\n",
    "        file = open(fileName,'r', encoding='utf-8-sig')\n",
    "        k = [self.proc(s) for s in file.readlines()]\n",
    "        k.sort()\n",
    "        return k\n",
    "\n",
    "    ### ignore it\n",
    "    def proc(self, s):\n",
    "        if s[-1] == '\\n': return s[:-1]\n",
    "        else: return s\n",
    "    \n",
    "    ### TODO (DO NOT FINISH THIS METHOD YET. YOU WILL BE ASKED FOR IT LATER) \n",
    "    def computeIDFs(self, documents):\n",
    "        n = len(documents)\n",
    "        for term in self.terms:\n",
    "            counter = 0\n",
    "            for d in documents:\n",
    "                if term in d.tokens:\n",
    "                    counter += 1\n",
    "            self.idfs.append(np.log(n/counter))\n",
    "    \n",
    "    ### TODO (DO NOT FINISH THIS METHOD YET. YOU WILL BE ASKED FOR IT LATER) \n",
    "    def computeCorM(self, documents):\n",
    "        for d1 in documents:\n",
    "            row = []\n",
    "            for d2 in documents:\n",
    "                z = d1.wordsSet.intersection(d2.wordsSet)\n",
    "                y = d1.wordsSet.union(d2.wordsSet)\n",
    "                if d1 == d2:\n",
    "                    row.append(-1)\n",
    "                else:\n",
    "                    print(len(d1.wordsSet))\n",
    "                    print(len(d2.wordsSet))\n",
    "                    row.append(len(z)/len(y))\n",
    "            self.corM.append(row)\n",
    "        \n",
    "\n",
    "### SOME DEBUG\n",
    "dictionary = Dictionary()\n",
    "print(dictionary.terms[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) Load files: here we load some example collection of documents. RAW_DOCUMENTS = just strings. Check if the documents are loaded correctly (e.g., print RAW_DOCUMENTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "David W. Aha:  Machine Learning Page\n Machine Learning Resources. Suggestions welcome. ... (WizRule); ZDM Scientific\n Ltd. Conference Announcements. Courses on Machine Learning. Data Repositories. ... \n Description: Comprehensive machine learning resources from Applications to Tutorials.\n\n"
    }
   ],
   "source": [
    "RAW_DOCUMENTS = cm.loadDocuments(\"documents.txt\")\n",
    "### SOME DEBUG\n",
    "print(RAW_DOCUMENTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['david', 'aha', 'machine', 'learning', 'page', 'machine', 'learning', 'resource', 'suggestion', 'welcome', 'wizrule', 'zdm', 'scientific', 'ltd', 'conference', 'announcement', 'course', 'machine', 'learning', 'data', 'repository', 'description', 'comprehensive', 'machine', 'learning', 'resource', 'from', 'application', 'tutorials']\n"
    }
   ],
   "source": [
    "### SOME DEBUG, JUST RUN; check if (a) common.py is imported correctly and (b) \n",
    "### tokens are correctly derived from some document (e.g., RAW_DOCUMENTS[0])\n",
    "print(cm.simpleTextProcessing(RAW_DOCUMENTS[0], re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3) Get acquainted with the below class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, doc_id, raw_document, dictionary):\n",
    "        self.doc_id = doc_id ### DOC ID, simply 0,1,2,3....\n",
    "        self.raw_document = raw_document ### raw data, i.e., string data\n",
    "        self.dictionary = dictionary # reference to the dictionary\n",
    "        \n",
    "        ### DOCUMENT REPRESENTATIONS\n",
    "        self.tokens = cm.simpleTextProcessing(raw_document, re) ### get terms\n",
    "        self.bow = [] # Bag Of Words (BOW - number of term occurences)\n",
    "        self.words = []\n",
    "        self.wordsSet = set()\n",
    "        self.tf = [] # TF representation\n",
    "        self.tf_idf = [] # TF-IDF representation\n",
    "\n",
    "    ### TODO - complete this method; it should compute a BOW representation\n",
    "    def computeBOW_Representation(self):\n",
    "        self.bow = []\n",
    "        self.wordsSet = set(self.tokens)\n",
    "        self.words = list(self.wordsSet)\n",
    "        for w in self.words:\n",
    "            self.bow.append([w, self.tokens.count(w)])\n",
    "    \n",
    "    ### TODO - complete this method; it should compute a TF representation\n",
    "    def computeTF_Representation(self):\n",
    "        self.tf = []\n",
    "        m = 0\n",
    "        for pair in self.bow:\n",
    "            if pair[1] > m:\n",
    "                m = pair[1]\n",
    "        for pair in self.bow:\n",
    "            self.tf.append(pair[1]/m)\n",
    "    \n",
    "    ### TODO - complete this method; it should compute a TFxIDF representation \n",
    "    ### (important: it should not be run before dictionary.idfs are not computed!)\n",
    "    def computeTF_IDF_Representation(self):\n",
    "        self.tf_idf = [] \n",
    "        for pair in self.bow:\n",
    "            # index w idf\n",
    "            if pair[0] in self.dictionary.terms:\n",
    "                termIndex = dictionary.terms.index(pair[0])\n",
    "                # wartość w idf\n",
    "                idfValue = dictionary.idfs[termIndex]\n",
    "            else:\n",
    "                idfValue = 0\n",
    "            # index w tf\n",
    "            tfIndex = self.bow.index(pair)\n",
    "            # wartość w tf\n",
    "            tfValue = self.tf[tfIndex]\n",
    "            \n",
    "            self.tf_idf.append(idfValue * tfValue)\n",
    "    \n",
    "    def computeRepresentations(self):\n",
    "        self.computeBOW_Representation()\n",
    "        self.computeTF_Representation()\n",
    "        self.computeTF_IDF_Representation()\n",
    "    \n",
    "documents = [Document(i, RAW_DOCUMENTS[i], dictionary) for i in range(len(RAW_DOCUMENTS))]\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4) Compute IDFs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['working', 4.477336814478207], ['www', 4.477336814478207], ['york', 4.477336814478207], ['young', 4.477336814478207], ['zdm', 4.477336814478207]]\n[['learning', 0.02298951822469878], ['machine', 0.02298951822469878], ['the', 0.4519851237430572], ['and', 0.7396671961948382], ['description', 0.8938178760220965]]\n"
    }
   ],
   "source": [
    "### TODO COMPUTE IDFS HERE (FINISH THE PROPER METHOD OF THE DICTIONARY CLASS - DO NOT FORGET TO RE-RUN THE CELL)\n",
    "dictionary.computeIDFs(documents)\n",
    "\n",
    "### SOME DEBUG\n",
    "res = [[dictionary.terms[i], dictionary.idfs[i]] for i in range(len(dictionary.terms))]\n",
    "res.sort(key = lambda x: x[1])\n",
    "# LEAST COMMON WORDS - HIGH IDF\n",
    "print(res[-5:])\n",
    "# MOST COMMON WORDS - LOW IDF\n",
    "print(res[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5) Compute the document representations (for each document run computeRepresentations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['suggestion', 1], ['course', 1], ['resource', 2], ['page', 1], ['wizrule', 1], ['aha', 1], ['announcement', 1], ['scientific', 1], ['application', 1], ['david', 1], ['data', 1], ['description', 1], ['comprehensive', 1], ['learning', 4], ['conference', 1], ['machine', 4], ['ltd', 1], ['from', 1], ['tutorials', 1], ['welcome', 1], ['repository', 1], ['zdm', 1]]\n"
    }
   ],
   "source": [
    "for d in documents: d.computeRepresentations()\n",
    "### SOME DEBUG (you should see some 4s - which terms are these?)\n",
    "print(documents[0].bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6) Finish the below method. It should compute and return a cosine similarity (v1 and v2 are two vectors - tf-idf representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.08769544271231881\n"
    }
   ],
   "source": [
    "### TODO \n",
    "def getSimilarity(v1, v2):\n",
    "    listOfSums = []\n",
    "    for term in dictionary.terms:\n",
    "        if term in v1.words:\n",
    "            tfIdfIndex = v1.words.index(term)\n",
    "            v1Value = v1.tf_idf[tfIdfIndex]\n",
    "        else:\n",
    "            v1Value = 0\n",
    "        if term in v2.words:\n",
    "            tfIdfIndex = v2.words.index(term)\n",
    "            v2Value = v2.tf_idf[tfIdfIndex]\n",
    "        else:\n",
    "            v2Value = 0\n",
    "        listOfSums.append(v1Value*v2Value)\n",
    "    nominator = sum(listOfSums)\n",
    "    sumV1 = 0\n",
    "    for tf_idf in v1.tf_idf:\n",
    "        sumV1 += tf_idf ** 2\n",
    "    sumV2 = 0\n",
    "    for tf_idf in v2.tf_idf:\n",
    "        sumV2 += tf_idf ** 2\n",
    "    denominator = (sumV1 * sumV2) ** (1/2)\n",
    "    return nominator/denominator\n",
    "        \n",
    "print(getSimilarity(documents[0], documents[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7) Run the below script for different queries. getTopResults seeks for documents being the most similar/relevant to the query. Do you find the results satisfactory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"machine learning\"\n",
    "# query = \"academic research\"\n",
    "# query = \"international conference\"\n",
    "# query = \"international conference washington\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RANK = 1 WITH SIMILARITY = 0.017145022655810024 | DOC ID = 63\nAI / Machine Learning Resources\n AI / Machine Learning Resources. General Machine Learning. The Journal\n of Machine Learning. MLnet Machine Learning Archive at GMD. The ... \n\n\nRANK = 2 WITH SIMILARITY = 0.012801913843626708 | DOC ID = 77\nMachine Learning\n Machine Learning. Machine Learning Home Page (Editor) Machine Learning Home\n Page (Publisher) Machine Learning Online by Kluwer Academic Publishers: ... \n\n\nRANK = 3 WITH SIMILARITY = 0.012340729913628307 | DOC ID = 34\nMachine Learning\n Machine Learning. Related Sites. Machine Learning Resources courtesy\n of David Aha A Machine Learning Tutorial a good overview of the ... \n\n\nRANK = 4 WITH SIMILARITY = 0.0110699100227987 | DOC ID = 81\nOxford University Machine Learning Group\n Machine Learning at the Computing Laboratory. ... Logic Programming and\n Learning and Intelligent Systems. Other Machine Learning Groups. ... \n\n\nRANK = 5 WITH SIMILARITY = 0.010455352603751217 | DOC ID = 62\nOpen Directory - Computers: Artificial Intelligence: Machine ... \n ... David W. Aha: Machine Learning Page - Comprehensive machine learning\n resources from Applications to Tutorials. Machine Learning ... \n\n\n"
    }
   ],
   "source": [
    "def getTopResults(query, documents, dictionary, similarity, top = 5):\n",
    "    qd = Document(-1, query, dictionary)\n",
    "    qd.computeRepresentations()\n",
    "    ranks = [[d, getSimilarity(d, qd)] for d in documents]\n",
    "    ranks.sort(key=lambda x: -x[1])\n",
    "    for i in range(top):\n",
    "        print(\"RANK = \" + str(i+1) + \" WITH SIMILARITY = \" + str(ranks[i][1]) + \" | DOC ID = \" + str(ranks[i][0].doc_id))\n",
    "        print(ranks[i][0].raw_document)\n",
    "        print(\"\")\n",
    "\n",
    "getTopResults(query, documents, dictionary, getSimilarity, top = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Query expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1) Finish dictionary.computeCorM method (see class Dictionary). It should generate a correlation matrix (correlation between terms).\n",
    "\n",
    "IMPORTANT: although corM[ i ][ i ] (for each i) should be 1.0, set it to -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10714285714285714, 0.08571428571428572, 0.10714285714285714, 0.14814814814814814, 0.06896551724137931, 0.05555555555555555, 0.16, 0.1111111111111111, 0.14814814814814814, 0.08, 0.16666666666666666, 0.0967741935483871, 0.13043478260869565, 0.09090909090909091, 0.1111111111111111, 0.14705882352941177, 0.10344827586206896, 0.07142857142857142, 0.09090909090909091, 0.07692307692307693, 0.13043478260869565, 0.07692307692307693, 0.0625, 0.12, 0.16, 0.20833333333333334, 0.08333333333333333, 0.08, 0.06666666666666667, 0.17391304347826086, 0.17857142857142858, 0.09523809523809523, 0.16, 0.1111111111111111, 0.07692307692307693, 0.10344827586206896, 0.10526315789473684, 0.16666666666666666, 0.15384615384615385, 0.125, 0.08571428571428572, 0.18181818181818182, 0.18518518518518517, 0.1282051282051282, 0.20588235294117646, 0.12, 0.125, 0.1, 0.13043478260869565, 0.08333333333333333, 0.17391304347826086, 0.25, 0.1111111111111111, 0.09090909090909091, 0.07407407407407407, 0.09523809523809523, 0.058823529411764705, 0.08333333333333333, 0.0625, 0.08333333333333333, 0.07692307692307693, 0.125, 0.07407407407407407, 0.10344827586206896, 0.19230769230769232, 0.16129032258064516, 0.1, -1, 0.09090909090909091, 0.09523809523809523, 0.16666666666666666, 0.09090909090909091, 0.13333333333333333, 0.12, 0.23529411764705882, 0.1111111111111111, 0.13636363636363635, 0.11538461538461539, 0.16666666666666666, 0.07142857142857142], [0.10344827586206896, 0.0625, 0.10344827586206896, 0.15, 0.08823529411764706, 0.13043478260869565, 0.12, 0.15, 0.08, 0.0967741935483871, 0.0, 0.17391304347826086, 0.125, 0.0967741935483871, 0.08695652173913043, 0.13043478260869565, 0.08, 0.09523809523809523, 0.08571428571428572, 0.2, 0.15789473684210525, 0.06666666666666667, 0.09090909090909091, 0.06060606060606061, 0.12, 0.13043478260869565, 0.10344827586206896, 0.05555555555555555, 0.15789473684210525, 0.14285714285714285, 0.07142857142857142, 0.14285714285714285, 0.08695652173913043, 0.08695652173913043, 0.15789473684210525, 0.2777777777777778, 0.12, 0.15, 0.07407407407407407, 0.35714285714285715, 0.13636363636363635, 0.18181818181818182, 0.08571428571428572, 0.12, 0.08571428571428572, 0.13333333333333333, 0.13043478260869565, 0.10344827586206896, 0.0967741935483871, 0.1, 0.12, 0.05263157894736842, 0.08823529411764706, 0.14285714285714285, 0.15, 0.08108108108108109, 0.2222222222222222, 0.09375, 0.15, 0.13043478260869565, 0.08333333333333333, 0.1111111111111111, 0.08695652173913043, 0.1875, 0.10344827586206896, 0.047619047619047616, 0.1111111111111111, 0.1, 0.2, 0.15, 0.13636363636363635, 0.12, 0.125, 0.10344827586206896, 0.2, 0.09090909090909091, -1, 0.11764705882352941, 0.09090909090909091, 0.3333333333333333, 0.1111111111111111, 0.14285714285714285, 0.13333333333333333, 0.08333333333333333, 0.16666666666666666, 0.13636363636363635, 0.4166666666666667, 0.08333333333333333], [0.10714285714285714, 0.13793103448275862, 0.06896551724137931, 0.1, 0.09090909090909091, 0.08695652173913043, 0.08, 0.1, 0.08333333333333333, 0.06451612903225806, 0.04, 0.08333333333333333, 0.13043478260869565, 0.06451612903225806, 0.09090909090909091, 0.08695652173913043, 0.08333333333333333, 0.1, 0.12121212121212122, 0.11538461538461539, 0.10526315789473684, 0.10714285714285714, 0.06060606060606061, 0.0967741935483871, 0.17391304347826086, 0.08695652173913043, 0.14814814814814814, 0.08823529411764706, 0.10526315789473684, 0.09523809523809523, 0.11538461538461539, 0.21052631578947367, 0.09090909090909091, 0.09090909090909091, 0.10526315789473684, 0.1, 0.08, 0.2222222222222222, 0.12, 0.125, 0.14285714285714285, 0.08695652173913043, 0.08823529411764706, 0.125, 0.05714285714285714, 0.14285714285714285, 0.08695652173913043, 0.14814814814814814, 0.1, 0.10526315789473684, 0.08, 0.11428571428571428, 0.125, 0.09523809523809523, 0.1, 0.11428571428571428, 0.16666666666666666, 0.0625, 0.1, 0.08695652173913043, 0.08695652173913043, 0.1875, 0.14285714285714285, 0.125, 0.06896551724137931, 0.05, 0.07407407407407407, 0.10526315789473684, 0.09523809523809523, 0.1, 0.09090909090909091, 0.125, 0.13043478260869565, 0.06896551724137931, 0.21428571428571427, 0.09523809523809523, 0.11764705882352941, -1, 0.09523809523809523, 0.11764705882352941, 0.11538461538461539, 0.09523809523809523, 0.14285714285714285, 0.08695652173913043, 0.1111111111111111, 0.09090909090909091, 0.14285714285714285, 0.08695652173913043], [0.09090909090909091, 0.08571428571428572, 0.09090909090909091, 0.125, 0.1388888888888889, 0.07142857142857142, 0.06666666666666667, 0.125, 0.06896551724137931, 0.11764705882352941, 0.03333333333333333, 0.10714285714285714, 0.10714285714285714, 0.05555555555555555, 0.07407407407407407, 0.1111111111111111, 0.06896551724137931, 0.08, 0.13513513513513514, 0.0625, 0.13043478260869565, 0.09090909090909091, 0.08108108108108109, 0.08333333333333333, 0.10344827586206896, 0.07142857142857142, 0.09090909090909091, 0.10526315789473684, 0.08333333333333333, 0.07692307692307693, 0.0967741935483871, 0.07692307692307693, 0.11538461538461539, 0.16, 0.13043478260869565, 0.08, 0.06666666666666667, 0.125, 0.17857142857142858, 0.09523809523809523, 0.11538461538461539, 0.1111111111111111, 0.07692307692307693, 0.10344827586206896, 0.07692307692307693, 0.10526315789473684, 0.1111111111111111, 0.09090909090909091, 0.08571428571428572, 0.08333333333333333, 0.10344827586206896, 0.1, 0.07894736842105263, 0.12, 0.125, 0.047619047619047616, 0.08333333333333333, 0.08333333333333333, 0.125, 0.1111111111111111, 0.07142857142857142, 0.2, 0.11538461538461539, 0.15, 0.058823529411764705, 0.08333333333333333, 0.0625, 0.08333333333333333, 0.12, 0.125, 0.07407407407407407, 0.18518518518518517, 0.14814814814814814, 0.09090909090909091, 0.1, 0.16666666666666666, 0.09090909090909091, 0.09523809523809523, -1, 0.09090909090909091, 0.0967741935483871, 0.12, 0.16666666666666666, 0.1111111111111111, 0.08695652173913043, 0.11538461538461539, 0.16666666666666666, 0.07142857142857142], [0.14285714285714285, 0.0967741935483871, 0.14285714285714285, 0.15, 0.12121212121212122, 0.13043478260869565, 0.16666666666666666, 0.15, 0.125, 0.13333333333333333, 0.0, 0.22727272727272727, 0.17391304347826086, 0.13333333333333333, 0.08695652173913043, 0.13043478260869565, 0.125, 0.09523809523809523, 0.11764705882352941, 0.25, 0.15789473684210525, 0.10344827586206896, 0.125, 0.09375, 0.12, 0.13043478260869565, 0.14285714285714285, 0.08571428571428572, 0.15789473684210525, 0.14285714285714285, 0.07142857142857142, 0.14285714285714285, 0.08695652173913043, 0.08695652173913043, 0.15789473684210525, 0.4375, 0.16666666666666666, 0.15, 0.11538461538461539, 0.35714285714285715, 0.13636363636363635, 0.3, 0.11764705882352941, 0.12, 0.11764705882352941, 0.13333333333333333, 0.13043478260869565, 0.14285714285714285, 0.13333333333333333, 0.1, 0.16666666666666666, 0.08108108108108109, 0.12121212121212122, 0.14285714285714285, 0.15, 0.1111111111111111, 0.2222222222222222, 0.12903225806451613, 0.15, 0.13043478260869565, 0.08333333333333333, 0.1111111111111111, 0.08695652173913043, 0.1875, 0.14285714285714285, 0.1, 0.1111111111111111, 0.1, 0.2, 0.15, 0.13636363636363635, 0.07692307692307693, 0.125, 0.14285714285714285, 0.2, 0.09090909090909091, 0.3333333333333333, 0.11764705882352941, 0.09090909090909091, -1, 0.1111111111111111, 0.14285714285714285, 0.13333333333333333, 0.08333333333333333, 0.16666666666666666, 0.19047619047619047, 0.4166666666666667, 0.08333333333333333], [0.05, 0.07317073170731707, 0.07692307692307693, 0.13793103448275862, 0.20512820512820512, 0.125, 0.08571428571428572, 0.1, 0.08823529411764706, 0.07317073170731707, 0.05714285714285714, 0.12121212121212122, 0.08823529411764706, 0.07317073170731707, 0.09375, 0.09090909090909091, 0.08823529411764706, 0.06451612903225806, 0.11627906976744186, 0.14285714285714285, 0.10344827586206896, 0.05, 0.06976744186046512, 0.07142857142857142, 0.08571428571428572, 0.09090909090909091, 0.07692307692307693, 0.043478260869565216, 0.14285714285714285, 0.0967741935483871, 0.05263157894736842, 0.13333333333333333, 0.09375, 0.09375, 0.10344827586206896, 0.1, 0.08571428571428572, 0.13793103448275862, 0.11428571428571428, 0.11538461538461539, 0.16666666666666666, 0.058823529411764705, 0.06666666666666667, 0.08571428571428572, 0.06666666666666667, 0.08, 0.09090909090909091, 0.10526315789473684, 0.07317073170731707, 0.10344827586206896, 0.08571428571428572, 0.06382978723404255, 0.09302325581395349, 0.0967741935483871, 0.1, 0.08695652173913043, 0.10344827586206896, 0.07142857142857142, 0.17857142857142858, 0.125, 0.09090909090909091, 0.1111111111111111, 0.06060606060606061, 0.16, 0.07692307692307693, 0.06666666666666667, 0.08108108108108109, 0.06666666666666667, 0.0967741935483871, 0.06451612903225806, 0.09375, 0.05555555555555555, 0.15625, 0.07692307692307693, 0.07692307692307693, 0.13333333333333333, 0.1111111111111111, 0.11538461538461539, 0.0967741935483871, 0.1111111111111111, -1, 0.0967741935483871, 0.17391304347826086, 0.058823529411764705, 0.14814814814814814, 0.09375, 0.125, 0.058823529411764705], [0.058823529411764705, 0.08571428571428572, 0.125, 0.17391304347826086, 0.17142857142857143, 0.1111111111111111, 0.10344827586206896, 0.17391304347826086, 0.06896551724137931, 0.15151515151515152, 0.03333333333333333, 0.14814814814814814, 0.10714285714285714, 0.22580645161290322, 0.11538461538461539, 0.15384615384615385, 0.06896551724137931, 0.125, 0.2, 0.0967741935483871, 0.23809523809523808, 0.125, 0.1111111111111111, 0.11428571428571428, 0.14285714285714285, 0.2, 0.2, 0.07692307692307693, 0.13043478260869565, 0.12, 0.0625, 0.12, 0.11538461538461539, 0.20833333333333334, 0.13043478260869565, 0.125, 0.28, 0.17391304347826086, 0.13793103448275862, 0.15, 0.11538461538461539, 0.15384615384615385, 0.13513513513513514, 0.18518518518518517, 0.13513513513513514, 0.23529411764705882, 0.15384615384615385, 0.125, 0.15151515151515152, 0.08333333333333333, 0.18518518518518517, 0.1, 0.1388888888888889, 0.16666666666666666, 0.2857142857142857, 0.1, 0.08333333333333333, 0.18181818181818182, 0.125, 0.25, 0.07142857142857142, 0.09090909090909091, 0.07407407407407407, 0.15, 0.09090909090909091, 0.04, 0.13333333333333333, 0.13043478260869565, 0.16666666666666666, 0.125, 0.11538461538461539, 0.10344827586206896, 0.14814814814814814, 0.16129032258064516, 0.1, 0.12, 0.14285714285714285, 0.09523809523809523, 0.12, 0.14285714285714285, 0.0967741935483871, -1, 0.10526315789473684, 0.1111111111111111, 0.13636363636363635, 0.16, 0.23529411764705882, 0.07142857142857142], [0.07407407407407407, 0.10714285714285714, 0.07407407407407407, 0.17647058823529413, 0.0967741935483871, 0.15, 0.08695652173913043, 0.1111111111111111, 0.14285714285714285, 0.06896551724137931, 0.043478260869565216, 0.14285714285714285, 0.09090909090909091, 0.06896551724137931, 0.15789473684210525, 0.09523809523809523, 0.14285714285714285, 0.1111111111111111, 0.12903225806451613, 0.125, 0.11764705882352941, 0.07407407407407407, 0.06451612903225806, 0.10344827586206896, 0.08695652173913043, 0.09523809523809523, 0.07407407407407407, 0.06060606060606061, 0.1875, 0.10526315789473684, 0.08, 0.16666666666666666, 0.15789473684210525, 0.1, 0.11764705882352941, 0.1111111111111111, 0.08695652173913043, 0.17647058823529413, 0.13043478260869565, 0.14285714285714285, 0.2222222222222222, 0.09523809523809523, 0.06060606060606061, 0.08695652173913043, 0.06060606060606061, 0.16666666666666666, 0.09523809523809523, 0.11538461538461539, 0.06896551724137931, 0.11764705882352941, 0.08695652173913043, 0.08823529411764706, 0.0967741935483871, 0.10526315789473684, 0.1111111111111111, 0.05714285714285714, 0.1875, 0.06666666666666667, 0.3333333333333333, 0.15, 0.15, 0.13333333333333333, 0.1, 0.14285714285714285, 0.07407407407407407, 0.11764705882352941, 0.08, 0.11764705882352941, 0.10526315789473684, 0.1111111111111111, 0.1, 0.08695652173913043, 0.2, 0.07407407407407407, 0.15384615384615385, 0.23529411764705882, 0.13333333333333333, 0.14285714285714285, 0.16666666666666666, 0.13333333333333333, 0.17391304347826086, 0.10526315789473684, -1, 0.09523809523809523, 0.2, 0.1, 0.16666666666666666, 0.09523809523809523], [0.08571428571428572, 0.08108108108108109, 0.11764705882352941, 0.07407407407407407, 0.075, 0.14285714285714285, 0.0625, 0.11538461538461539, 0.06451612903225806, 0.1111111111111111, 0.03125, 0.1, 0.06451612903225806, 0.08108108108108109, 0.06896551724137931, 0.10344827586206896, 0.2222222222222222, 0.07407407407407407, 0.07317073170731707, 0.058823529411764705, 0.12, 0.15151515151515152, 0.07692307692307693, 0.07894736842105263, 0.0967741935483871, 0.06666666666666667, 0.15151515151515152, 0.07317073170731707, 0.07692307692307693, 0.1111111111111111, 0.058823529411764705, 0.07142857142857142, 0.10714285714285714, 0.10714285714285714, 0.07692307692307693, 0.07407407407407407, 0.0625, 0.20833333333333334, 0.09375, 0.08695652173913043, 0.06896551724137931, 0.18518518518518517, 0.1282051282051282, 0.0967741935483871, 0.07317073170731707, 0.09523809523809523, 0.06666666666666667, 0.15151515151515152, 0.1111111111111111, 0.037037037037037035, 0.0967741935483871, 0.12195121951219512, 0.075, 0.07142857142857142, 0.11538461538461539, 0.045454545454545456, 0.07692307692307693, 0.17142857142857143, 0.07407407407407407, 0.10344827586206896, 0.06666666666666667, 0.08333333333333333, 0.06896551724137931, 0.08695652173913043, 0.05555555555555555, 0.037037037037037035, 0.058823529411764705, 0.07692307692307693, 0.07142857142857142, 0.11538461538461539, 0.06896551724137931, 0.0967741935483871, 0.1, 0.08571428571428572, 0.09090909090909091, 0.1111111111111111, 0.08333333333333333, 0.08695652173913043, 0.1111111111111111, 0.08333333333333333, 0.058823529411764705, 0.1111111111111111, 0.09523809523809523, -1, 0.125, 0.10714285714285714, 0.15, 0.10344827586206896], [0.06451612903225806, 0.09375, 0.1, 0.14285714285714285, 0.08571428571428572, 0.17391304347826086, 0.11538461538461539, 0.14285714285714285, 0.12, 0.09375, 0.037037037037037035, 0.16666666666666666, 0.12, 0.09375, 0.13043478260869565, 0.125, 0.12, 0.09090909090909091, 0.11428571428571428, 0.14814814814814814, 0.15, 0.06451612903225806, 0.08823529411764706, 0.09090909090909091, 0.11538461538461539, 0.125, 0.1, 0.05405405405405406, 0.21052631578947367, 0.13636363636363635, 0.06896551724137931, 0.19047619047619047, 0.13043478260869565, 0.08333333333333333, 0.15, 0.14285714285714285, 0.11538461538461539, 0.2, 0.07142857142857142, 0.17647058823529413, 0.18181818181818182, 0.08, 0.08333333333333333, 0.11538461538461539, 0.08333333333333333, 0.125, 0.125, 0.13793103448275862, 0.09375, 0.09523809523809523, 0.11538461538461539, 0.07894736842105263, 0.11764705882352941, 0.13636363636363635, 0.14285714285714285, 0.07894736842105263, 0.15, 0.09090909090909091, 0.2, 0.17391304347826086, 0.125, 0.10526315789473684, 0.08333333333333333, 0.17647058823529413, 0.1, 0.045454545454545456, 0.10714285714285714, 0.09523809523809523, 0.13636363636363635, 0.09090909090909091, 0.13043478260869565, 0.07407407407407407, 0.16666666666666666, 0.1, 0.11764705882352941, 0.13636363636363635, 0.16666666666666666, 0.1111111111111111, 0.08695652173913043, 0.16666666666666666, 0.14814814814814814, 0.13636363636363635, 0.2, 0.125, -1, 0.13043478260869565, 0.2, 0.08], [0.08823529411764706, 0.11428571428571428, 0.15625, 0.12, 0.13513513513513514, 0.10714285714285714, 0.13793103448275862, 0.16666666666666666, 0.10344827586206896, 0.14705882352941177, 0.03225806451612903, 0.18518518518518517, 0.14285714285714285, 0.11428571428571428, 0.07142857142857142, 0.14814814814814814, 0.10344827586206896, 0.07692307692307693, 0.16216216216216217, 0.12903225806451613, 0.17391304347826086, 0.12121212121212122, 0.1388888888888889, 0.1111111111111111, 0.13793103448275862, 0.10714285714285714, 0.15625, 0.10256410256410256, 0.125, 0.11538461538461539, 0.06060606060606061, 0.11538461538461539, 0.1111111111111111, 0.1111111111111111, 0.125, 0.16666666666666666, 0.13793103448275862, 0.16666666666666666, 0.13333333333333333, 0.14285714285714285, 0.1111111111111111, 0.14814814814814814, 0.13157894736842105, 0.13793103448275862, 0.13157894736842105, 0.1, 0.10714285714285714, 0.15625, 0.14705882352941177, 0.08, 0.17857142857142858, 0.0975609756097561, 0.13513513513513514, 0.11538461538461539, 0.16666666666666666, 0.0975609756097561, 0.08, 0.14285714285714285, 0.12, 0.14814814814814814, 0.10714285714285714, 0.08695652173913043, 0.07142857142857142, 0.14285714285714285, 0.12121212121212122, 0.08, 0.09375, 0.08, 0.11538461538461539, 0.12, 0.1111111111111111, 0.1, 0.14285714285714285, 0.15625, 0.09523809523809523, 0.11538461538461539, 0.13636363636363635, 0.09090909090909091, 0.11538461538461539, 0.19047619047619047, 0.09375, 0.16, 0.1, 0.10714285714285714, 0.13043478260869565, -1, 0.2222222222222222, 0.06896551724137931], [0.16, 0.10714285714285714, 0.16, 0.17647058823529413, 0.13333333333333333, 0.15, 0.13636363636363635, 0.25, 0.09090909090909091, 0.14814814814814814, 0.043478260869565216, 0.2631578947368421, 0.14285714285714285, 0.10714285714285714, 0.1, 0.2777777777777778, 0.09090909090909091, 0.1111111111111111, 0.12903225806451613, 0.22727272727272727, 0.26666666666666666, 0.11538461538461539, 0.13793103448275862, 0.10344827586206896, 0.19047619047619047, 0.15, 0.16, 0.09375, 0.1875, 0.16666666666666666, 0.08, 0.16666666666666666, 0.15789473684210525, 0.15789473684210525, 0.1875, 0.3333333333333333, 0.13636363636363635, 0.25, 0.13043478260869565, 0.45454545454545453, 0.15789473684210525, 0.35294117647058826, 0.12903225806451613, 0.19047619047619047, 0.16666666666666666, 0.16666666666666666, 0.15, 0.16, 0.14814814814814814, 0.11764705882352941, 0.19047619047619047, 0.08823529411764706, 0.13333333333333333, 0.16666666666666666, 0.25, 0.08823529411764706, 0.26666666666666666, 0.14285714285714285, 0.17647058823529413, 0.21052631578947367, 0.15, 0.13333333333333333, 0.15789473684210525, 0.23076923076923078, 0.11538461538461539, 0.05555555555555555, 0.125, 0.11764705882352941, 0.23529411764705882, 0.25, 0.15789473684210525, 0.13636363636363635, 0.2, 0.16, 0.25, 0.16666666666666666, 0.4166666666666667, 0.14285714285714285, 0.16666666666666666, 0.4166666666666667, 0.125, 0.23529411764705882, 0.16666666666666666, 0.15, 0.2, 0.2222222222222222, -1, 0.09523809523809523], [0.05555555555555555, 0.05263157894736842, 0.08571428571428572, 0.11538461538461539, 0.04878048780487805, 0.06666666666666667, 0.0967741935483871, 0.07407407407407407, 0.06451612903225806, 0.05263157894736842, 0.0, 0.06451612903225806, 0.06451612903225806, 0.1111111111111111, 0.06896551724137931, 0.06666666666666667, 0.1, 0.07407407407407407, 0.047619047619047616, 0.058823529411764705, 0.07692307692307693, 0.05555555555555555, 0.05, 0.05128205128205128, 0.0625, 0.06666666666666667, 0.05555555555555555, 0.047619047619047616, 0.07692307692307693, 0.1111111111111111, 0.058823529411764705, 0.07142857142857142, 0.06896551724137931, 0.06896551724137931, 0.07692307692307693, 0.07407407407407407, 0.0625, 0.07407407407407407, 0.06060606060606061, 0.08695652173913043, 0.06896551724137931, 0.06666666666666667, 0.047619047619047616, 0.0625, 0.047619047619047616, 0.09523809523809523, 0.06666666666666667, 0.08571428571428572, 0.08108108108108109, 0.037037037037037035, 0.0625, 0.045454545454545456, 0.04878048780487805, 0.07142857142857142, 0.07407407407407407, 0.045454545454545456, 0.07692307692307693, 0.05128205128205128, 0.07407407407407407, 0.06666666666666667, 0.06666666666666667, 0.08333333333333333, 0.06896551724137931, 0.08695652173913043, 0.05555555555555555, 0.037037037037037035, 0.058823529411764705, 0.07692307692307693, 0.07142857142857142, 0.07407407407407407, 0.06896551724137931, 0.0625, 0.06451612903225806, 0.05555555555555555, 0.09090909090909091, 0.07142857142857142, 0.08333333333333333, 0.08695652173913043, 0.07142857142857142, 0.08333333333333333, 0.058823529411764705, 0.07142857142857142, 0.09523809523809523, 0.10344827586206896, 0.08, 0.06896551724137931, 0.09523809523809523, -1]]\n"
    }
   ],
   "source": [
    "### TODO - COMPLETE THE computeCorM METHOD (see one of the first cells)\n",
    "dictionary.computeCorM(documents)\n",
    "print(dictionary.corM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2) Finish the below method. For each term in the query (you must parse the query, see getTopResults() method), find another term which is the most correlated with the input term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "international\n"
    }
   ],
   "source": [
    "# query = \"machine\"\n",
    "# query = \"algorithm\"\n",
    "# query = \"learning\"\n",
    "query = \"conference\"\n",
    "# query = \"research\"\n",
    "# query = \"concept\"\n",
    "\n",
    "def suggestKeywords(query, dictionary):\n",
    "    ### TODO\n",
    "    matrix = []\n",
    "    for term in dictionary.terms:\n",
    "        row = []\n",
    "        suma = 0\n",
    "        for d in documents:\n",
    "            if term in d.wordsSet:\n",
    "                idx = d.words.index(term)\n",
    "                row.append(d.bow[idx][1])\n",
    "                suma+= d.bow[idx][1] ** 2\n",
    "            else:\n",
    "                row.append(0)\n",
    "        row = [i / (suma ** (1 / 2)) for i in row]\n",
    "        matrix.append(row)\n",
    "    matrix = np.asarray(matrix)\n",
    "    finalM = matrix@matrix.T\n",
    "    idx = dictionary.terms.index(query)\n",
    "    for i in range(len(finalM)):\n",
    "        finalM[i, i] *= -1\n",
    "    m = max(finalM[idx])\n",
    "    xd = 0\n",
    "    for i in range(len(finalM[idx])):\n",
    "        if finalM[idx, i] == m:\n",
    "            xd = i\n",
    "    \n",
    "    print(dictionary.terms[xd])\n",
    "        \n",
    "suggestKeywords(query, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2) Rocchio algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\overrightarrow{q_{m}} = \\alpha \\overrightarrow{q} + \\left(\\beta \\cdot \\dfrac{1}{|D_{r}|} \\sum_{\\overrightarrow{D_j} \\in D_{r}} \\overrightarrow{D_j} \\right) - \\left(\\gamma \\cdot \\dfrac{1}{|D_{nr}|} \\sum_{\\overrightarrow{D_j} \\in D_{nr}} \\overrightarrow{D_j} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1) Firstly, run the below code. Observe the results. Assume that we do not like the first and the second result (Docs 63 and 77). However, assume that docs 29 and 36 are satisfactory. Now, modfify the method. It should alter the query vector, according to Rocchio algorithm. Check the result for the above considered scenario (relevant docs = 29 and 36; not relevant = 63 and 77). Check the results for different values of alpha, beta, and gamma coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "14\n22\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-4ffe2a89caef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mgetTopResults_Rocchio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"machine learning\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetSimilarity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-4ffe2a89caef>\u001b[0m in \u001b[0;36mgetTopResults_Rocchio\u001b[1;34m(query, documents, dictionary, similarity, rel_docs, nrel_docs, alpha, beta, gamma, top)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrel_docs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbSum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mbSum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbSum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def getTopResults_Rocchio(query, \n",
    "                          documents, \n",
    "                          dictionary, \n",
    "                          similarity, \n",
    "                          rel_docs = [29, 36],\n",
    "                          nrel_docs = [63, 77],\n",
    "                          alpha = 0.5,\n",
    "                          beta = 0.3,\n",
    "                          gamma = 0.2,\n",
    "                          top = 10):\n",
    "    qd = Document(-1, query, dictionary)\n",
    "    qd.computeRepresentations()\n",
    "    ##### TODO: MODIFY qd.tf_idf HERE\n",
    "    \n",
    "    A = [alpha * i for i in qd.tf_idf]\n",
    "    print(len(documents[29].tf_idf))\n",
    "    bSum = [0 for i in documents[0].tf_idf]\n",
    "    print(len(bSum))\n",
    "    for i in rel_docs:\n",
    "        for b in range(len(bSum)):\n",
    "            bSum[b] += documents[i].tf_idf[b]\n",
    "    print(bSum)\n",
    "\n",
    "    #####\n",
    "    ranks = [[d, getSimilarity(d.tf_idf, qd.tf_idf)] for d in documents]\n",
    "    ranks.sort(key=lambda x: -x[1])\n",
    "    for i in range(top):\n",
    "        print(\"RANK = \" + str(i+1) + \" WITH SIMILARITY = \" + str(ranks[i][1]) + \" | DOC ID = \" + str(ranks[i][0].doc_id))\n",
    "        print(ranks[i][0].raw_document)\n",
    "        print(\"\")\n",
    "\n",
    "getTopResults_Rocchio(\"machine learning\", documents, dictionary, getSimilarity, top = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3) WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1) Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.nltk.org/install.html\n",
    "\n",
    "import nltk \n",
    "\n",
    "nltk.download()\n",
    "\n",
    "https://www.nltk.org/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ntlk' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-2cc05f592f46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mntlk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ntlk' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "\n",
    "ntlk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: synset = (from wiki) (information science) A set of one or more synonyms that are interchangeable in some context without changing the truth value of the proposition in which they are embedded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.2) Display sysents for \"machine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\mikol/nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\mikol/nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-277acff9a003>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'machine'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\mikol/nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\mikol\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "wn.synsets('machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.3) Display all definitions (.definition()) for synsets (machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "print(wn.synsets('machine').definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.4) For each synset (machine), display its hypernym (a word with a broad meaning constituting a category into which words with more specific meanings fall; a superordinate. For example, colour is a hypernym of red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "print(wn.synets('machine').hypernym())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "See: http://www.nltk.org/howto/wordnet.html\n",
    "for more examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}